import { useCallback, useRef } from 'react';
import toast from 'react-hot-toast';

import { CloudLLMClient } from '@/lib/cloud-llm';
import { generateAiFeedbackStream, listAiSummaries } from '@/lib/tauri';
import { useAppStore } from '@/store';

const DEFAULT_AI_SUMMARY_LIMIT = 10;

/**
 * Unified AI Pipeline Hook
 * Combines categorization and feedback generation into a single sequential pipeline
 *
 * Pipeline Flow:
 * 1. Stage: Categorizing - AI categorizes the dump content
 * 2. Stage: Generating Feedback - AI generates feedback (streaming) based on categorized content
 */
export function useAiPipeline() {
  // Zustand store selectors
  const aiSummaries = useAppStore((state) => state.aiSummaries);
  const selectedSummaryIndex = useAppStore((state) => state.selectedSummaryIndex);
  const summariesError = useAppStore((state) => state.summariesError);
  const isPipelineRunning = useAppStore((state) => state.isGeneratingAiFeedback);
  const pipelineStage = useAppStore((state) => state.pipelineStage);
  const streamingAiText = useAppStore((state) => state.streamingAiText);

  const setAiSummaries = useAppStore((state) => state.setAiSummaries);
  const setSelectedSummaryIndex = useAppStore((state) => state.setSelectedSummaryIndex);
  const setSummariesError = useAppStore((state) => state.setSummariesError);
  const setIsPipelineRunning = useAppStore((state) => state.setIsGeneratingAiFeedback);
  const setPipelineStage = useAppStore((state) => state.setPipelineStage);
  const setStreamingAiText = useAppStore((state) => state.setStreamingAiText);

  // Refs for streaming
  const streamingBufferRef = useRef('');
  const streamingTimerRef = useRef<number | null>(null);
  const streamingCleanupRef = useRef<(() => void) | null>(null);

  /**
   * Load AI summaries from storage
   */
  const loadAiSummaries = useCallback(async () => {
    try {
      setSummariesError(null);
      const summaries = await listAiSummaries(DEFAULT_AI_SUMMARY_LIMIT);
      setAiSummaries(summaries);
      const currentIndex = useAppStore.getState().selectedSummaryIndex;
      if (!summaries.length) {
        setSelectedSummaryIndex(0);
      } else {
        setSelectedSummaryIndex(Math.min(currentIndex, summaries.length - 1));
      }
    } catch (error) {
      if (import.meta.env.DEV)
        console.error('[hoego] AI summaries ë¡œë“œ ì‹¤íŒ¨', error);
      setSummariesError(error instanceof Error ? error.message : String(error));
      setAiSummaries([]);
      setSelectedSummaryIndex(0);
    }
  }, [setAiSummaries, setSelectedSummaryIndex, setSummariesError]);

  /**
   * Stage 1: Categorize dump content (with UI display)
   * @param content Current markdown content
   * @returns Categorized markdown content
   */
  const categorizeDump = useCallback(async (content: string): Promise<string> => {
    // Empty content check
    if (!content || content.trim().length === 0) {
      toast.error('ì¹´í…Œê³ ë¦¬í™”í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.');
      return content;
    }

    // Minimum content check (at least 50 characters)
    if (content.trim().length < 50) {
      toast.error('ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 50ì ì´ìƒ ì‘ì„±í•´ì£¼ì„¸ìš”.');
      return content;
    }

    try {
      // Check if API key exists
      const hasKey = await CloudLLMClient.hasApiKey('openai');
      if (!hasKey) {
        toast.error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.');
        return content;
      }

      // Call AI categorization
      const response = await CloudLLMClient.complete({
        messages: [
          {
            role: 'user',
            content: buildCategorizationPrompt(content),
          },
        ],
        model: 'gpt-4o-mini', // Fast and cost-effective
        temperature: 0.1, // Very low for consistent formatting
        max_tokens: 3000, // More tokens for detailed analysis
        system_prompt: 'You are an expert time analyst specializing in personal productivity. Analyze daily activity dumps with precision, calculate time spent per category, and present data in professional markdown tables.',
      });

      const categorizedSection = response.content.trim();

      // Validate response
      if (!categorizedSection || categorizedSection.length === 0) {
        toast.error('ì¹´í…Œê³ ë¦¬í™” ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        return content;
      }

      // Display categorization result in UI immediately
      setStreamingAiText(categorizedSection);

      // Return original content without modification
      // Categorization result is only displayed in UI, not saved to file
      return content;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : String(err);
      if (import.meta.env.DEV) {
        console.error('[hoego] Dump ì¹´í…Œê³ ë¦¬í™” ì‹¤íŒ¨:', err);
      }

      // User-friendly error messages
      if (errorMessage.includes('API key')) {
        toast.error('API í‚¤ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      } else if (errorMessage.includes('network') || errorMessage.includes('fetch')) {
        toast.error('ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      } else if (errorMessage.includes('rate limit')) {
        toast.error('API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      } else {
        toast.error(`ì¹´í…Œê³ ë¦¬í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${errorMessage}`);
      }

      throw err; // Re-throw to stop pipeline
    }
  }, [setStreamingAiText]);

  /**
   * Stage 2: Generate AI feedback (streaming)
   */
  const generateFeedback = useCallback(async () => {
    // Clear previous content and start fresh
    // Only show feedback, not categorization result
    setStreamingAiText('');

    streamingBufferRef.current = '';

    // Event subscription: delta/complete/error
    const unsubs: Array<() => void> = [];
    const cleanup = () => {
      unsubs.forEach((u) => {
        try {
          u();
        } catch {}
      });
      if (streamingTimerRef.current) {
        clearInterval(streamingTimerRef.current);
        streamingTimerRef.current = null;
      }
      streamingBufferRef.current = '';
      setStreamingAiText('');
      streamingCleanupRef.current = null;
    };

    streamingCleanupRef.current = cleanup;

    try {
      const { listen } = await import('@tauri-apps/api/event');

      const unDelta = await listen<{ text: string }>(
        'ai_feedback_stream_delta',
        (e) => {
          const t = e.payload?.text || '';
          if (!t) return;
          streamingBufferRef.current += t;
          if (!streamingTimerRef.current) {
            streamingTimerRef.current = window.setInterval(() => {
              if (!streamingBufferRef.current) return;
              const currentText = useAppStore.getState().streamingAiText;
              const next = currentText + streamingBufferRef.current;
              streamingBufferRef.current = '';
              setStreamingAiText(next);
            }, 50);
          }
        }
      );
      unsubs.push(unDelta);

      const unComplete = await listen<{
        filename: string;
        path: string;
        createdAt?: string;
      }>('ai_feedback_stream_complete', async () => {
        cleanup();
        await loadAiSummaries();
        setSelectedSummaryIndex(0);
        setPipelineStage('complete');
        setIsPipelineRunning(false);
      });
      unsubs.push(unComplete);

      const unError = await listen<{ message: string }>(
        'ai_feedback_stream_error',
        (e) => {
          cleanup();
          const msg = e.payload?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
          toast.error(`AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${msg}`);
          setPipelineStage('idle');
          setIsPipelineRunning(false);
        }
      );
      unsubs.push(unError);

      await generateAiFeedbackStream();
    } catch (error) {
      if (import.meta.env.DEV)
        console.error('[hoego] AI í”¼ë“œë°± ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹¤íŒ¨', error);
      toast.error(
        `AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${
          error instanceof Error ? error.message : String(error)
        }`
      );
      cleanup();
      setPipelineStage('idle');
      setIsPipelineRunning(false);
      throw error;
    }
  }, [loadAiSummaries, setSelectedSummaryIndex, setPipelineStage, setIsPipelineRunning, setStreamingAiText]);

  /**
   * Main pipeline handler
   * Runs categorization, then feedback generation sequentially
   * @param content Current markdown content
   * @param onContentUpdate Callback to update the content after categorization (not used anymore)
   */
  const handleRunPipeline = useCallback(async (
    content: string,
    onContentUpdate: (categorizedContent: string) => Promise<void>
  ) => {
    if (isPipelineRunning) return;

    setIsPipelineRunning(true);
    setPipelineStage('categorizing');

    try {
      // Stage 1: Categorization (display only, don't save to file)
      await categorizeDump(content);

      // Skip saving - categorization result is only shown in UI

      // Stage 2: AI Feedback (streaming)
      setPipelineStage('generating_feedback');
      await generateFeedback();

      // Note: Pipeline completion is handled in the 'ai_feedback_stream_complete' event
    } catch (error) {
      // Error already handled in individual stages
      setPipelineStage('idle');
      setIsPipelineRunning(false);
    }
  }, [isPipelineRunning, categorizeDump, generateFeedback, setIsPipelineRunning, setPipelineStage]);

  /**
   * Get label for AI summary entry
   */
  const getSummaryLabel = useCallback((summary: { filename: string; createdAt?: string }) => {
    if (!summary?.createdAt) {
      return summary.filename;
    }
    const date = new Date(summary.createdAt);
    if (Number.isNaN(date.getTime())) {
      return summary.filename;
    }
    const datePart = date.toLocaleDateString('ko-KR', {
      month: 'short',
      day: 'numeric',
      weekday: 'short',
    });
    const timePart = date.toLocaleTimeString('ko-KR', {
      hour: '2-digit',
      minute: '2-digit',
    });
    return `${datePart} ${timePart}`;
  }, []);

  return {
    // State
    aiSummaries,
    selectedSummaryIndex,
    summariesError,
    isPipelineRunning,
    pipelineStage,
    streamingAiText,
    streamingCleanupRef,

    // Actions
    setSelectedSummaryIndex,
    loadAiSummaries,
    handleRunPipeline,
    getSummaryLabel,
  };
}

// ============================================================================
// Helper Functions (from useDumpCategorization)
// ============================================================================

interface ParsedEntry {
  time: string;
  timeInMinutes: number;
  content: string;
  durationMinutes?: number;
  durationText?: string;
}

/**
 * Parse timestamps from content
 */
function parseTimestamps(content: string): ParsedEntry[] {
  const lines = content.split('\n');
  const entries: ParsedEntry[] = [];

  for (const line of lines) {
    // Find (HH:MM:SS) pattern
    const match = line.match(/\((\d{2}):(\d{2}):(\d{2})\)/);
    if (match && match[1] && match[2] && match[3]) {
      const hh = match[1];
      const mm = match[2];
      const ss = match[3];
      const timeInMinutes = parseInt(hh, 10) * 60 + parseInt(mm, 10);
      const cleanContent = line
        .replace(/\s*\(\d{2}:\d{2}:\d{2}\)\s*$/, '')
        .replace(/^\s*[\*\-]\s*/, '')
        .trim();

      entries.push({
        time: `${hh}:${mm}:${ss}`,
        timeInMinutes,
        content: cleanContent,
      });
    }
  }

  return entries;
}

/**
 * Calculate durations between timestamps
 */
function calculateDurations(entries: ParsedEntry[]): ParsedEntry[] {
  const result: ParsedEntry[] = [];

  for (let i = 0; i < entries.length - 1; i++) {
    const current = entries[i];
    const next = entries[i + 1];
    if (current && next) {
      const duration = next.timeInMinutes - current.timeInMinutes;
      result.push({
        ...current,
        durationMinutes: duration,
        durationText: formatDuration(duration),
      });
    }
  }

  // Last entry (no duration)
  const lastEntry = entries[entries.length - 1];
  if (lastEntry) {
    result.push({
      ...lastEntry,
      durationMinutes: 0,
      durationText: '-',
    });
  }

  return result;
}

/**
 * Format duration (minutes â†’ "Xì‹œê°„ Yë¶„")
 */
function formatDuration(minutes: number): string {
  if (minutes <= 0) return '-';

  const hours = Math.floor(minutes / 60);
  const mins = minutes % 60;

  if (hours > 0 && mins > 0) {
    return `${hours}ì‹œê°„ ${mins}ë¶„`;
  } else if (hours > 0) {
    return `${hours}ì‹œê°„`;
  } else {
    return `${mins}ë¶„`;
  }
}

/**
 * Build AI categorization prompt (Few-shot learning + time data)
 */
function buildCategorizationPrompt(content: string): string {
  // Parse timestamps and calculate durations
  const parsed = parseTimestamps(content);
  const withDurations = calculateDurations(parsed);

  // Calculate total activity time
  const totalMinutes = withDurations.reduce(
    (sum, entry) => sum + (entry.durationMinutes || 0),
    0
  );
  const totalTime = formatDuration(totalMinutes);

  // Build activity list with time information
  const activitiesWithTime = withDurations
    .map((e, i) => `${i + 1}. [${e.time}] ${e.content} (ì†Œìš”: ${e.durationText})`)
    .join('\n');

  return `ë‹¹ì‹ ì€ í•˜ë£¨ dump ë‚´ìš©ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì‹œê°„ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ dumpë¥¼ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ì‚¬ìš© í˜„í™©ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ì›ì¹™:**
1. ì•„ë˜ì— ì œê³µëœ ì •í™•í•œ ì‹œê°„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ì´ë¯¸ ê³„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤)
2. ë¹„ìŠ·í•œ í™œë™ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë¬¶ì–´ì„œ ì‹œê°„ ì§‘ê³„
3. ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ê³¼ ë¹„ìœ¨ í‘œì‹œ
4. ê° ì¹´í…Œê³ ë¦¬ë³„ ì„¸ë¶€ í™œë™ ëª©ë¡ ì‘ì„±
5. **ì¤‘ìš”**: í™œë™ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìƒì‚°ì ì¸ ì‹œê°„ê³¼ ë‚­ë¹„ëœ ì‹œê°„ì„ êµ¬ë¶„
6. **ì¤‘ìš”**: ì‚¬ìš©ìê°€ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì œì•ˆ ì œê³µ

---

**ì˜ˆì‹œ - ì‹œê°„ì´ ê³„ì‚°ëœ í™œë™ ëª©ë¡:**

1. [09:00:00] ì˜¤ì „ 9ì‹œ ê¸°ìƒ (ì†Œìš”: 30ë¶„)
2. [09:30:00] ì•„ì¹¨ ë¨¹ê³  ìƒ¤ì›Œ (ì†Œìš”: 30ë¶„)
3. [10:00:00] ëŸ¬ë‹ 3km, ë°œëª© í†µì¦ (ì†Œìš”: 45ë¶„)
4. [10:45:00] ì—…ë¬´ ì‹œì‘ - MVP ê°œë°œ (ì†Œìš”: 1ì‹œê°„ 45ë¶„)
5. [12:30:00] ì ì‹¬ ì‹ì‚¬ (ì†Œìš”: 1ì‹œê°„)
6. [13:30:00] ì—…ë¬´ ì¬ê°œ - API ì‘ì—… (ì†Œìš”: 2ì‹œê°„ 30ë¶„)
7. [16:00:00] ìœ íŠœë¸Œ ì‹œì²­ (ì†Œìš”: -)

**ì˜ˆì‹œ ì¶œë ¥:**

## ğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ì‚¬ìš© ë¶„ì„

| ì¹´í…Œê³ ë¦¬ | ì´ ì‹œê°„ | ë¹„ìœ¨ |
|---------|---------|------|
| ì‘ì—… (ê°œë°œ/ì—…ë¬´/ë¹Œë“œ) | 4ì‹œê°„ 15ë¶„ | 60.7% |
| ê°œì¸ ë£¨í‹´ (ì‹ì‚¬/ìƒ¤ì›Œ/ì •ë¦¬ ë“±) | 1ì‹œê°„ 30ë¶„ | 21.4% |
| ìš´ë™ | 45ë¶„ | 10.7% |
| ì˜¤ë½/ì·¨ë¯¸ | 30ë¶„ | 7.2% |

### ì‘ì—… (ê°œë°œ/ì—…ë¬´/ë¹Œë“œ) - 4ì‹œê°„ 15ë¶„
- ì—…ë¬´ ì‹œì‘ - MVP ê°œë°œ
- ì—…ë¬´ ì¬ê°œ - API ì‘ì—…

### ê°œì¸ ë£¨í‹´ (ì‹ì‚¬/ìƒ¤ì›Œ/ì •ë¦¬ ë“±) - 1ì‹œê°„ 30ë¶„
- ì˜¤ì „ 9ì‹œ ê¸°ìƒ
- ì•„ì¹¨ ë¨¹ê³  ìƒ¤ì›Œ
- ì ì‹¬ ì‹ì‚¬

### ìš´ë™ - 45ë¶„
- ëŸ¬ë‹ 3km, ë°œëª© í†µì¦

### ì˜¤ë½/ì·¨ë¯¸ - 30ë¶„
- ìœ íŠœë¸Œ ì‹œì²­

## ğŸ’¡ ì˜¤ëŠ˜ì˜ ì¸ì‚¬ì´íŠ¸

### âš¡ ìƒì‚°ì ì¸ ì‹œê°„ (High Quality Time)
- ì—…ë¬´ ì‹œì‘ - MVP ê°œë°œ (1ì‹œê°„ 45ë¶„)
- ì—…ë¬´ ì¬ê°œ - API ì‘ì—… (2ì‹œê°„ 30ë¶„)
- ìš´ë™ (45ë¶„)
â†’ **ì´ ìƒì‚°ì  ì‹œê°„: 5ì‹œê°„**

### âš ï¸ ê°œì„  ê°€ëŠ¥í•œ ì‹œê°„ (Potential Waste)
- ìœ íŠœë¸Œ ì‹œì²­ (30ë¶„) - íœ´ì‹ í•„ìš”í–ˆì„ ê°€ëŠ¥ì„±
â†’ **ì´ ê°œì„  ê°€ëŠ¥ ì‹œê°„: 30ë¶„**

### ğŸ¯ ê°œì„  ì œì•ˆ
1. **íœ´ì‹ì´ í•„ìš”í•  ë•Œ**: ìœ íŠœë¸Œ ëŒ€ì‹  ì§§ì€ ì‚°ì±…ì´ë‚˜ ìŠ¤íŠ¸ë ˆì¹­ ì¶”ì²œ
2. **ì—ë„ˆì§€ ê´€ë¦¬**: ì˜¤ì „ì— ì§‘ì¤‘ ì‘ì—…, ì˜¤í›„ì— ê°€ë²¼ìš´ ì‘ì—… ë°°ì¹˜

---

**ì´ì œ ë‹¤ìŒ í™œë™ë“¤ì„ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:**

**ì´ í™œë™ ê°œìˆ˜:** ${withDurations.length}ê°œ
**ì „ì²´ ì‹œê°„ ë²”ìœ„:** ${parsed[0]?.time || 'ì—†ìŒ'} ~ ${parsed[parsed.length - 1]?.time || 'ì—†ìŒ'}
**ì´ í™œë™ ì‹œê°„:** ${totalTime}

**ì‹œê°„ì´ ê³„ì‚°ëœ í™œë™ ëª©ë¡:**
${activitiesWithTime}

**ë¶„ì„ ê²°ê³¼:**`;
}
